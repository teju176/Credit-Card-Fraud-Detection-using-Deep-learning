{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 314 #used to help randomly select the data points\n",
    "TEST_PCT = 0.2 # 20% of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\") \n",
    "df.head(n=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #secondary check on the size of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any() #check to see if any values are null, which there are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['Class'], sort = True) #class comparison 0=Normal 1=Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = df[df.Class == 0] #save normal_df observations into a separate df\n",
    "fraud_df = df[df.Class == 1] #do the same for frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df.Amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df.Amount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique() # 0 = no fraud, 1 = fraudulent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize and Scale Data\n",
    "#data = df.drop(['Time'], axis=1) #if you think the var is unimportant\n",
    "df_norm = df\n",
    "df_norm['Time'] = StandardScaler().fit_transform(df_norm['Time'].values.reshape(-1, 1))\n",
    "df_norm['Amount'] = StandardScaler().fit_transform(df_norm['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing Training and Test Set\n",
    "train_x, test_x = train_test_split(df_norm, test_size=TEST_PCT, random_state=RANDOM_SEED)\n",
    "train_x = train_x[train_x.Class == 0] #where normal transactions\n",
    "train_x = train_x.drop(['Class'], axis=1) #drop the class column\n",
    "\n",
    "\n",
    "test_y = test_x['Class'] #save the class column for the test set\n",
    "test_x = test_x.drop(['Class'], axis=1) #drop the class column\n",
    "\n",
    "train_x = train_x.values #transform to ndarray\n",
    "test_x = test_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227468, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = train_x.shape[1] #num of columns, 30\n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) #i.e. 7\n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1778/1778 [==============================] - 6s 3ms/step - loss: 0.9318 - accuracy: 0.4074 - val_loss: 0.8347 - val_accuracy: 0.5783\n",
      "Epoch 2/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7909 - accuracy: 0.5932 - val_loss: 0.7998 - val_accuracy: 0.6285\n",
      "Epoch 3/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7614 - accuracy: 0.6246 - val_loss: 0.7875 - val_accuracy: 0.6353\n",
      "Epoch 4/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7508 - accuracy: 0.6371 - val_loss: 0.7800 - val_accuracy: 0.6438\n",
      "Epoch 5/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7521 - accuracy: 0.6450 - val_loss: 0.7702 - val_accuracy: 0.6578\n",
      "Epoch 6/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7310 - accuracy: 0.6579 - val_loss: 0.7621 - val_accuracy: 0.6694\n",
      "Epoch 7/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7346 - accuracy: 0.6677 - val_loss: 0.7576 - val_accuracy: 0.6753\n",
      "Epoch 8/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7230 - accuracy: 0.6798 - val_loss: 0.7546 - val_accuracy: 0.6846\n",
      "Epoch 9/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7206 - accuracy: 0.6842 - val_loss: 0.7524 - val_accuracy: 0.6830\n",
      "Epoch 10/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7077 - accuracy: 0.6903 - val_loss: 0.7499 - val_accuracy: 0.6946\n",
      "Epoch 11/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7273 - accuracy: 0.6918 - val_loss: 0.7483 - val_accuracy: 0.7007\n",
      "Epoch 12/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7441 - accuracy: 0.6955 - val_loss: 0.7490 - val_accuracy: 0.7002\n",
      "Epoch 13/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7232 - accuracy: 0.6999 - val_loss: 0.7482 - val_accuracy: 0.7024\n",
      "Epoch 14/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6887 - accuracy: 0.7031 - val_loss: 0.7468 - val_accuracy: 0.7045\n",
      "Epoch 15/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7015 - accuracy: 0.7070 - val_loss: 0.7438 - val_accuracy: 0.7122\n",
      "Epoch 16/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7146 - accuracy: 0.7112 - val_loss: 0.7433 - val_accuracy: 0.7115\n",
      "Epoch 17/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7055 - accuracy: 0.7122 - val_loss: 0.7421 - val_accuracy: 0.7124\n",
      "Epoch 18/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.6938 - accuracy: 0.7120 - val_loss: 0.7418 - val_accuracy: 0.7164\n",
      "Epoch 19/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7055 - accuracy: 0.7156 - val_loss: 0.7410 - val_accuracy: 0.7151\n",
      "Epoch 20/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7071 - accuracy: 0.7120 - val_loss: 0.7411 - val_accuracy: 0.7171\n",
      "Epoch 21/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7102 - accuracy: 0.7149 - val_loss: 0.7405 - val_accuracy: 0.7152\n",
      "Epoch 22/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7199 - accuracy: 0.7153 - val_loss: 0.7395 - val_accuracy: 0.7119\n",
      "Epoch 23/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7094 - accuracy: 0.7161 - val_loss: 0.7390 - val_accuracy: 0.7153\n",
      "Epoch 24/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6958 - accuracy: 0.7151 - val_loss: 0.7381 - val_accuracy: 0.7167\n",
      "Epoch 25/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7085 - accuracy: 0.7140 - val_loss: 0.7382 - val_accuracy: 0.7182\n",
      "Epoch 26/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7261 - accuracy: 0.7136 - val_loss: 0.7381 - val_accuracy: 0.7141\n",
      "Epoch 27/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7033 - accuracy: 0.7156 - val_loss: 0.7378 - val_accuracy: 0.7183\n",
      "Epoch 28/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7035 - accuracy: 0.7164 - val_loss: 0.7381 - val_accuracy: 0.7125\n",
      "Epoch 29/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7035 - accuracy: 0.7169 - val_loss: 0.7381 - val_accuracy: 0.7150\n",
      "Epoch 30/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7028 - accuracy: 0.7174 - val_loss: 0.7373 - val_accuracy: 0.7174\n",
      "Epoch 31/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7019 - accuracy: 0.7163 - val_loss: 0.7369 - val_accuracy: 0.7194\n",
      "Epoch 32/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7029 - accuracy: 0.7196 - val_loss: 0.7379 - val_accuracy: 0.7164\n",
      "Epoch 33/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7095 - accuracy: 0.7189 - val_loss: 0.7374 - val_accuracy: 0.7130\n",
      "Epoch 34/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7020 - accuracy: 0.7211 - val_loss: 0.7385 - val_accuracy: 0.7095\n",
      "Epoch 35/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7158 - accuracy: 0.7189 - val_loss: 0.7375 - val_accuracy: 0.7146\n",
      "Epoch 36/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.6952 - accuracy: 0.7184 - val_loss: 0.7370 - val_accuracy: 0.7150\n",
      "Epoch 37/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.6973 - accuracy: 0.7171 - val_loss: 0.7366 - val_accuracy: 0.7143\n",
      "Epoch 38/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7085 - accuracy: 0.7175 - val_loss: 0.7357 - val_accuracy: 0.7180\n",
      "Epoch 39/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6985 - accuracy: 0.7181 - val_loss: 0.7371 - val_accuracy: 0.7164\n",
      "Epoch 40/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7018 - accuracy: 0.7160 - val_loss: 0.7364 - val_accuracy: 0.7116\n",
      "Epoch 41/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6875 - accuracy: 0.7156 - val_loss: 0.7365 - val_accuracy: 0.7114\n",
      "Epoch 42/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.6955 - accuracy: 0.7179 - val_loss: 0.7363 - val_accuracy: 0.7144\n",
      "Epoch 43/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6930 - accuracy: 0.7184 - val_loss: 0.7362 - val_accuracy: 0.7141\n",
      "Epoch 44/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6962 - accuracy: 0.7193 - val_loss: 0.7360 - val_accuracy: 0.7133\n",
      "Epoch 45/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7103 - accuracy: 0.7189 - val_loss: 0.7360 - val_accuracy: 0.7179\n",
      "Epoch 46/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6842 - accuracy: 0.7168 - val_loss: 0.7352 - val_accuracy: 0.7178\n",
      "Epoch 47/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.6917 - accuracy: 0.7169 - val_loss: 0.7374 - val_accuracy: 0.7098\n",
      "Epoch 48/50\n",
      "1778/1778 [==============================] - 3s 2ms/step - loss: 0.7228 - accuracy: 0.7171 - val_loss: 0.7357 - val_accuracy: 0.7122\n",
      "Epoch 49/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7052 - accuracy: 0.7162 - val_loss: 0.7357 - val_accuracy: 0.7159\n",
      "Epoch 50/50\n",
      "1778/1778 [==============================] - 4s 2ms/step - loss: 0.7131 - accuracy: 0.7170 - val_loss: 0.7350 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "#Model Training and Logging\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_x, test_x),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>True_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56962.000000</td>\n",
       "      <td>56962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.734975</td>\n",
       "      <td>0.002019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.165660</td>\n",
       "      <td>0.044887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.045243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252267</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.403755</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.638371</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.810488</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction_error    True_class\n",
       "count          56962.000000  56962.000000\n",
       "mean               0.734975      0.002019\n",
       "std                3.165660      0.044887\n",
       "min                0.045243      0.000000\n",
       "25%                0.252267      0.000000\n",
       "50%                0.403755      0.000000\n",
       "75%                0.638371      0.000000\n",
       "max              190.810488      1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reconstruction Error Check\n",
    "test_x_predictions = autoencoder.predict(test_x)\n",
    "mse = np.mean(np.power(test_x - test_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_y})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential([\n",
    "    Dense(units=16, kernel_initializer='uniform', input_dim=30, activation='relu'),\n",
    "    Dense(units=18, kernel_initializer='uniform', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(20, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(24, kernel_initializer='uniform', activation='relu'),\n",
    "    Dense(1, kernel_initializer='uniform', activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 18)                306       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                380       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,711\n",
      "Trainable params: 1,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "17089/17089 [==============================] - 29s 2ms/step - loss: 0.0227 - accuracy: 0.9984\n",
      "Epoch 2/2\n",
      "17089/17089 [==============================] - 27s 2ms/step - loss: 0.0032 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f020339988>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train, batch_size=15, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "\n",
      "And the Score is  99.91924166679382 %\n"
     ]
    }
   ],
   "source": [
    "score = clf.evaluate(X_test, Y_test, batch_size=128)\n",
    "print('\\nAnd the Score is ', score[1] * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
